#!/usr/bin/env python3
"""
GR00T ì¶”ë¡  ì‹œìŠ¤í…œ ìµœì†Œ í…ŒìŠ¤íŠ¸
ë‹¨ì¼ ì¶”ë¡  ìˆ˜í–‰ ë° Action Token ê²€ì¦
"""

import os
import sys
import time
import logging
import numpy as np
import torch
from typing import Dict, Any, Optional
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
sys.path.append(str(Path(__file__).parent))

# í•„ìš”í•œ ëª¨ë“ˆ import
try:
    from model.gr00t_interface import DualPiperGR00TInterface
    from data.integrated_pipeline import IntegratedDataPipeline
    from utils.data_types import RobotData
    from config.hardware_config import get_hardware_config
except ImportError as e:
    print(f"âŒ Import Error: {e}")
    print("Make sure you're running from the project root directory")
    sys.exit(1)


class GR00TMinimalTester:
    """GR00T ìµœì†Œ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self, use_mock_data: bool = True):
        """
        í…ŒìŠ¤í„° ì´ˆê¸°í™”
        
        Args:
            use_mock_data: Mock ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        """
        self.use_mock_data = use_mock_data
        self.logger = logging.getLogger("GR00TMinimalTester")
        
        # ì„¤ì •
        self.embodiment_name = "dual_piper_arm"
        # self.embodiment_name = "agibot_genie1"
        self.model_path = "nvidia/GR00T-N1.5-3B"  # ê³µì‹ ëª¨ë¸ ê²½ë¡œë¡œ ìˆ˜ì •
        
        # ì»´í¬ë„ŒíŠ¸ë“¤
        self.gr00t_interface: Optional[DualPiperGR00TInterface] = None
        self.data_pipeline: Optional[IntegratedDataPipeline] = None
        
        print(f"ğŸ”§ GR00T Minimal Tester initialized (Mock: {use_mock_data})")
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
    
    def check_dependencies(self) -> bool:
        """ì˜ì¡´ì„± í™•ì¸"""
        print("\nğŸ“‹ Checking dependencies...")
        
        try:
            # PyTorch í™•ì¸
            print(f"  PyTorch: {torch.__version__}")
            if torch.cuda.is_available():
                print(f"  CUDA: Available (GPU: {torch.cuda.get_device_name()})")
            else:
                print(f"  CUDA: Not available (using CPU)")
            
            # NumPy í™•ì¸
            print(f"  NumPy: {np.__version__}")
            
            # GR00T ëª¨ë“ˆ í™•ì¸
            try:
                from gr00t.model.policy import Gr00tPolicy
                print(f"  GR00T Policy: Available")
            except ImportError:
                print(f"  GR00T Policy: Not available (will use mock)")
                return False
            
            return True
            
        except Exception as e:
            print(f"  âŒ Dependency check failed: {e}")
            return False
    
    def create_mock_robot_data(self) -> RobotData:
        """Mock ë¡œë´‡ ë°ì´í„° ìƒì„±"""
        print("\nğŸ­ Creating mock robot data...")
        
        # í˜„ì¬ ì‹œê°„
        timestamp = time.time()
        
        # GR00T í¬ë§·ì— ë§ëŠ” Mock ë¹„ë””ì˜¤ ë°ì´í„° (ì˜ˆì‹œ: left_arm_d435, right_arm_d435)
        mock_video = {
            'video.left_arm_d435': np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8),
            'video.right_arm_d435': np.random.randint(0, 255, (224, 224, 3), dtype=np.uint8),
        }
        
        # GR00T í¬ë§·ì— ë§ëŠ” Mock ìƒíƒœ ë°ì´í„°
        mock_state = {
            'state.left_arm_joint_position': np.random.uniform(-1, 1, 7).astype(np.float32),
            'state.right_arm_joint_position': np.random.uniform(-1, 1, 7).astype(np.float32),
            'state.left_effector_position': np.random.uniform(-0.5, 0.5, 6).astype(np.float32),
            'state.right_effector_position': np.random.uniform(-0.5, 0.5, 6).astype(np.float32),
        }
        
        # Mock ì•¡ì…˜ ë°ì´í„° (GR00T í¬ë§·)
        mock_action = {
            'action.left_arm_joint_position': np.random.uniform(-1, 1, 7).astype(np.float32),
            'action.right_arm_joint_position': np.random.uniform(-1, 1, 7).astype(np.float32),
            'action.left_effector_position': np.random.uniform(-0.5, 0.5, 6).astype(np.float32),
            'action.right_effector_position': np.random.uniform(-0.5, 0.5, 6).astype(np.float32),
        }
        
        # Mock í…ìŠ¤íŠ¸ ëª…ë ¹ (GR00T í¬ë§·)
        mock_text = "Pick up the red cube and place it on the table"
        mock_language = {"annotation.language.instruction": mock_text}
        
        # RobotData ê°ì²´ ìƒì„± ë° ì†ì„± í• ë‹¹
        robot_data = RobotData()
        robot_data.timestamp = timestamp
        robot_data.video_data = mock_video
        robot_data.state_data = mock_state
        robot_data.action_data = mock_action
        robot_data.language_data = mock_language
        
        print(f"  âœ… Mock robot data created")
        print(f"    Video frames: {len(mock_video)}")
        print(f"    State keys: {list(mock_state.keys())}")
        print(f"    Text command: {mock_text[:50]}...")
        
        return robot_data
    
    def create_gr00t_observations(self, robot_data: RobotData) -> Dict[str, Any]:
        """ë¡œë´‡ ë°ì´í„°ë¥¼ GR00T ê´€ì°° í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        print("\nğŸ”„ Converting to GR00T observations...")
        
        try:
            # ë¹„ë””ì˜¤ ë°ì´í„° ë³€í™˜ (Batch dimension ì¶”ê°€)
            video_tensor = []
            for camera_name, frame in robot_data.video_data.items():
                # (H, W, C) -> (C, H, W) -> (1, C, H, W)
                frame_tensor = torch.from_numpy(frame).permute(2, 0, 1).unsqueeze(0).float() / 255.0
                video_tensor.append(frame_tensor)
            video_tensor = torch.cat(video_tensor, dim=0)  # (N_cameras, C, H, W)
            video_tensor = video_tensor.unsqueeze(0)  # (1, N_cameras, C, H, W)
            
            # ìƒíƒœ ë°ì´í„° ë³€í™˜ (ê° state keyë³„ë¡œ ì´ì–´ë¶™ì„)
            state_vector = []
            for key in [
                'state.left_arm_joint_position',
                'state.right_arm_joint_position',
                'state.left_effector_position',
                'state.right_effector_position',
            ]:
                state_vector.extend(robot_data.state_data[key])
            state_tensor = torch.tensor(state_vector, dtype=torch.float32).unsqueeze(0)  # (1, state_dim)
            
            # ì•¡ì…˜ ë°ì´í„° ë³€í™˜ (ê° action keyë³„ë¡œ ì´ì–´ë¶™ì„)
            action_vector = []
            for key in [
                'action.left_arm_joint_position',
                'action.right_arm_joint_position',
                'action.left_effector_position',
                'action.right_effector_position',
            ]:
                action_vector.extend(robot_data.action_data[key])
            action_tensor = torch.tensor(action_vector, dtype=torch.float32).unsqueeze(0)  # (1, action_dim)

            # í…ìŠ¤íŠ¸ ë°ì´í„° (GR00T í¬ë§·)
            text_data = robot_data.language_data.get("annotation.language.instruction", "")
            language_tensor = np.array([text_data])

            observations = {
                'video': video_tensor,
                'state': state_tensor,
                'action': action_tensor,
                'language': language_tensor
            }
            
            print(f"  âœ… GR00T observations created")
            print(f"    Video shape: {video_tensor.shape}")
            print(f"    State shape: {state_tensor.shape}")
            print(f"    Language: {text_data}")
            
            return observations
            
        except Exception as e:
            print(f"  âŒ Conversion failed: {e}")
            raise
    
    def initialize_gr00t_interface(self) -> bool:
        """GR00T ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”"""
        print("\nğŸ§  Initializing GR00T interface...")
        
        try:
            # ë””ë°”ì´ìŠ¤ ì„¤ì •
            device = "cuda" if torch.cuda.is_available() else "cpu"
            
            # GR00T ì¸í„°í˜ì´ìŠ¤ ìƒì„±
            self.gr00t_interface = DualPiperGR00TInterface(
                model_path=self.model_path,
                embodiment_name=self.embodiment_name,
                device=device,
                use_mock_data=self.use_mock_data
            )
            
            # ëª¨ë¸ ì •ë³´ í™•ì¸
            model_info = self.gr00t_interface.get_model_info()
            print(f"  âœ… GR00T interface initialized")
            print(f"    Model: {model_info.get('model_path', 'Unknown')}")
            print(f"    Embodiment: {model_info.get('embodiment_name', 'Unknown')}")
            print(f"    Device: {model_info.get('device', 'Unknown')}")
            
            return True
            
        except Exception as e:
            print(f"  âŒ GR00T interface initialization failed: {e}")
            return False
    
    def test_single_inference(self, observations: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ë‹¨ì¼ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""
        print("\nğŸ¯ Testing single inference...")
        
        try:
            # ê´€ì°° ë°ì´í„° ê²€ì¦
            print("  ğŸ“‹ Validating observations...")
            if self.gr00t_interface is None:
                print("  âŒ GR00T interface is None")
                return None
            is_valid = self.gr00t_interface.validate_observations(observations)
            if not is_valid:
                print("  âŒ Observations validation failed")
                return None
            
            print("  âœ… Observations validated")
            
            # ì¶”ë¡  ìˆ˜í–‰
            print("  ğŸš€ Performing inference...")
            start_time = time.time()
            
            action = self.gr00t_interface.get_action_from_observations(observations)
            
            inference_time = time.time() - start_time
            
            print(f"  âœ… Inference completed in {inference_time*1000:.2f}ms")
            
            return action
            
        except Exception as e:
            print(f"  âŒ Inference failed: {e}")
            return None
    
    def analyze_action_token(self, action: Dict[str, Any]):
        """Action Token ë¶„ì„"""
        print("\nğŸ” Analyzing Action Token...")
        
        try:
            print(f"  ğŸ“Š Action Token Structure:")
            print(f"    Total keys: {len(action)}")
            
            # ê° ì•¡ì…˜ í‚¤ ë¶„ì„
            for key, value in action.items():
                print(f"\n    ğŸ”‘ {key}:")
                
                if isinstance(value, np.ndarray):
                    print(f"      Type: numpy.ndarray")
                    print(f"      Shape: {value.shape}")
                    print(f"      Dtype: {value.dtype}")
                    print(f"      Range: [{value.min():.4f}, {value.max():.4f}]")
                    
                    # ì²« ëª‡ ê°œ ê°’ ì¶œë ¥
                    if value.size <= 20:
                        print(f"      Values: {value.flatten()}")
                    else:
                        print(f"      First 5 values: {value.flatten()[:5]}")
                        
                elif isinstance(value, dict):
                    print(f"      Type: dict")
                    print(f"      Sub-keys: {list(value.keys())}")
                    
                    for sub_key, sub_value in value.items():
                        if isinstance(sub_value, np.ndarray):
                            print(f"        {sub_key}: {sub_value.shape} {sub_value.dtype}")
                        else:
                            print(f"        {sub_key}: {type(sub_value)} = {sub_value}")
                            
                else:
                    print(f"      Type: {type(value)}")
                    print(f"      Value: {value}")
            
            # ì•¡ì…˜ í•´ì„
            print(f"\n  ğŸ¯ Action Interpretation:")
            
            # ì¼ë°˜ì ì¸ ë¡œë´‡ ì•¡ì…˜ íŒ¨í„´ í™•ì¸
            if 'arm_action' in action:
                arm_action = action['arm_action']
                if isinstance(arm_action, np.ndarray):
                    print(f"    Arm actions detected: {arm_action.shape}")
                    if arm_action.shape[-1] == 14:  # 14 DOF dual arm
                        print(f"    Left arm (7 joints): {arm_action[:7]}")
                        print(f"    Right arm (7 joints): {arm_action[7:]}")
                    
            if 'gripper_action' in action:
                gripper_action = action['gripper_action']
                if isinstance(gripper_action, np.ndarray):
                    print(f"    Gripper actions: {gripper_action}")
                    
            if 'terminate' in action:
                terminate = action['terminate']
                print(f"    Terminate signal: {terminate}")
            
        except Exception as e:
            print(f"  âŒ Action analysis failed: {e}")
    
    def run_test(self) -> bool:
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("ğŸš€ Starting GR00T Minimal Inference Test")
        print("=" * 60)
        
        try:
            # 1. ë¡œê¹… ì„¤ì •
            self.setup_logging()
            
            # 2. ì˜ì¡´ì„± í™•ì¸
            if not self.check_dependencies():
                print("âŒ Dependency check failed")
                return False
            
            # 3. Mock ë°ì´í„° ìƒì„±
            robot_data = self.create_mock_robot_data()
            
            # 4. GR00T ê´€ì°° ë°ì´í„° ë³€í™˜
            observations = self.create_gr00t_observations(robot_data)
            
            # 5. GR00T ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
            if not self.initialize_gr00t_interface():
                print("âŒ GR00T interface initialization failed")
                return False
            
            # 6. ë‹¨ì¼ ì¶”ë¡  í…ŒìŠ¤íŠ¸
            action = self.test_single_inference(observations)
            
            if action is None:
                print("âŒ Inference test failed")
                return False
            
            # 7. Action Token ë¶„ì„
            self.analyze_action_token(action)
            
            # 8. ì„±ëŠ¥ í†µê³„
            if self.gr00t_interface is not None:
                stats = self.gr00t_interface.get_performance_stats()
                print(f"\nğŸ“ˆ Performance Statistics:")
                print(f"    Total inferences: {stats.get('total_inferences', 0)}")
                print(f"    Average inference time: {stats.get('avg_inference_time_ms', 0):.2f}ms")
                print(f"    Uptime: {stats.get('uptime_seconds', 0):.2f}s")
            else:
                print("[WARN] GR00T interface is None, cannot print performance stats.")
            
            print("\n" + "=" * 60)
            print("âœ… GR00T Minimal Inference Test PASSED")
            return True
            
        except Exception as e:
            print(f"\nâŒ Test failed with exception: {e}")
            import traceback
            traceback.print_exc()
            return False
        
        finally:
            # ì •ë¦¬ ì‘ì—…
            if self.gr00t_interface:
                self.gr00t_interface.stop_data_pipeline()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("GR00T Minimal Inference Test")
    print("This test will perform a single inference to verify the GR00T system")
    
    # ì‚¬ìš©ì ì˜µì…˜
    use_mock = True  # ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©ì‹œ Falseë¡œ ë³€ê²½
    
    if use_mock:
        print("\nâš ï¸  Using MOCK data (no real model required)")
    else:
        print("\nğŸ”¥ Using REAL model (requires actual GR00T model)")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    tester = GR00TMinimalTester(use_mock_data=use_mock)
    success = tester.run_test()
    
    if success:
        print("\nğŸ‰ Test completed successfully!")
        print("The GR00T inference system is working correctly.")
    else:
        print("\nğŸ’¥ Test failed!")
        print("Please check the error messages above.")
    
    return 0 if success else 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
