"""
GR00T ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤
ê¸°ì¡´ GR00T Policyë¥¼ ìš°ë¦¬ ì‹œìŠ¤í…œì— ë§ê²Œ ë˜í•‘
"""

import time
from typing import Dict, Any, Optional, Union
from pathlib import Path
import logging
import torch
import numpy as np

# GR00T ê¸°ë³¸ import
from gr00t.model.policy import Gr00tPolicy, BasePolicy
from gr00t.data.dataset import ModalityConfig
from gr00t.data.embodiment_tags import EmbodimentTag
from gr00t.data.transform.base import ComposedModalityTransform
from gr00t.experiment.data_config import DATA_CONFIG_MAP

# ìš°ë¦¬ ì‹œìŠ¤í…œ import
from utils.data_types import RobotData
from data.unified_data_pipeline import UnifiedDataPipeline


class DualPiperGR00TInterface:
    """Dual Piper ë¡œë´‡ìš© GR00T ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(
        self,
        model_path: str,
        embodiment_name: str = "dual_piper_arm",
        denoising_steps: Optional[int] = None,
        device: Union[int, str] = "cuda" if torch.cuda.is_available() else "cpu",
        use_mock_data: bool = False
    ):
        """
        GR00T ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            model_path: GR00T ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ ë˜ëŠ” HuggingFace Hub ID
            embodiment_name: ë¡œë´‡ embodiment ì´ë¦„ (DATA_CONFIG_MAPì˜ í‚¤)
            denoising_steps: Flow matching ë””ë…¸ì´ì§• ìŠ¤í… ìˆ˜
            device: ì‹¤í–‰ ì¥ì¹˜
            use_mock_data: Mock ë°ì´í„° ì‚¬ìš© ì—¬ë¶€
        """
        self.model_path = model_path
        self.embodiment_name = embodiment_name
        self.device = torch.device(device if torch.cuda.is_available() and device == "cuda" else "cpu")
        self.use_mock_data = use_mock_data
        
        # ë¡œê¹… ì„¤ì •
        self.logger = logging.getLogger("DualPiperGR00TInterface")
        
        # ì„¤ì • ë° Transform ë¡œë“œ
        self._load_config_and_transforms()
        
        # GR00T Policy ì´ˆê¸°í™”
        self._initialize_gr00t_policy(denoising_steps)
        
        # ë°ì´í„° íŒŒì´í”„ë¼ì¸ (ì„ íƒì )
        self.data_pipeline: Optional[UnifiedDataPipeline] = None
        
        # ì„±ëŠ¥ í†µê³„
        self.total_inferences = 0
        self.total_inference_time = 0.0
        self.start_time = time.time()
        
        self.logger.info(f"GR00T interface initialized for {embodiment_name}")
    
    def _load_config_and_transforms(self):
        """ì„¤ì • ë° Transform ë¡œë“œ"""
        if self.embodiment_name not in DATA_CONFIG_MAP:
            available = list(DATA_CONFIG_MAP.keys())
            raise ValueError(f"Unknown embodiment: {self.embodiment_name}. Available: {available}")
        
        # GR00T ë°ì´í„° ì„¤ì • ë¡œë“œ
        self.data_config = DATA_CONFIG_MAP[self.embodiment_name]
        self.modality_config = self.data_config.modality_config()
        self.modality_transform = self.data_config.transform()
        
        self.logger.info(f"Loaded config for embodiment: {self.embodiment_name}")
    
    def _initialize_gr00t_policy(self, denoising_steps: Optional[int]):
        """GR00T Policy ì´ˆê¸°í™”"""
        try:
            # Embodiment tag ì„¤ì •
            if self.embodiment_name in ["dual_piper_arm"]:
                embodiment_tag = "dual_piper_arm"  # Enum ë° ë©”íƒ€ë°ì´í„°ì™€ ì¼ì¹˜
            else:
                embodiment_tag = self.embodiment_name
            
            # GR00T Policy ìƒì„±
            self.policy = Gr00tPolicy(
                model_path=self.model_path,
                embodiment_tag=embodiment_tag,
                modality_config=self.modality_config,
                modality_transform=self.modality_transform,
                denoising_steps=denoising_steps,
                device=str(self.device)
            )
            
            self.logger.info("GR00T policy initialized successfully")
            
        except Exception as e:
            self.logger.error(f"Failed to initialize GR00T policy: {e}")
            raise
    
    def start_data_pipeline(self) -> bool:
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì‹œì‘"""
        if self.data_pipeline is not None:
            self.logger.warning("Data pipeline already started")
            return True
        try:
            self.data_pipeline = UnifiedDataPipeline(
                embodiment_name=self.embodiment_name,
                use_mock=self.use_mock_data
            )
            success = self.data_pipeline.start()
            if success:
                self.logger.info("Data pipeline started")
            else:
                self.logger.error("Failed to start data pipeline")
            return success
        except Exception as e:
            self.logger.error(f"Error starting data pipeline: {e}")
            return False
    
    def stop_data_pipeline(self):
        """ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì¤‘ì§€"""
        if self.data_pipeline is not None:
            self.data_pipeline.stop()
            self.data_pipeline = None
            self.logger.info("Data pipeline stopped")
    
    def _ensure_gr00t_format(self, observations: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê´€ì°° ë°ì´í„°ê°€ GR00T í˜•ì‹ì¸ì§€ í™•ì¸í•˜ê³  í•„ìš”ì‹œ ë³€í™˜
        
        Args:
            observations: ê´€ì°° ë°ì´í„°
            
        Returns:
            GR00T í˜•ì‹ì˜ ë°ì´í„°
        """
        # ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹ì¸ì§€ í™•ì¸ (ê°œë³„ ë¹„ë””ì˜¤ í‚¤ê°€ ìˆëŠ”ì§€)
        has_individual_video_keys = any(key.startswith('video.') for key in observations.keys())
        
        if has_individual_video_keys:
            # ì´ë¯¸ ì˜¬ë°”ë¥¸ í˜•ì‹ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ë°˜í™˜
            self.logger.debug("Data already in correct GR00T format")
            return observations
        else:
            # ë³€í™˜ì´ í•„ìš”í•œ ê²½ìš°
            self.logger.debug("Converting data to GR00T format")
            return self._convert_to_gr00t_format(observations)
    
    def get_action_from_observations(self, observations: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê´€ì°° ë°ì´í„°ë¡œë¶€í„° ì•¡ì…˜ ì˜ˆì¸¡
        
        Args:
            observations: GR00T í˜•ì‹ì˜ ê´€ì°° ë°ì´í„°
            
        Returns:
            ì˜ˆì¸¡ëœ ì•¡ì…˜ ë”•ì…”ë„ˆë¦¬
        """
        start_time = time.time()
        
        try:
            # GR00Tê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ë³€í™˜
            gr00t_data = self._ensure_gr00t_format(observations)
            
            # GR00T Policyë¡œ ì•¡ì…˜ ì˜ˆì¸¡ (ë³€í™˜ íŒŒì´í”„ë¼ì¸ ìš°íšŒ)
            action_dict = self.policy.get_action(gr00t_data)
            
            # í†µê³„ ì—…ë°ì´íŠ¸
            inference_time = time.time() - start_time
            self.total_inference_time += inference_time
            self.total_inferences += 1
            
            # ì•¡ì…˜ í›„ì²˜ë¦¬ (í•„ìš”ì‹œ)
            processed_action = self._postprocess_action(action_dict)
            
            return processed_action
            
        except Exception as e:
            self.logger.error(f"Action prediction failed: {e}")
            return self._get_safe_action()
    
    def _convert_to_gr00t_format(self, observations: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê´€ì°° ë°ì´í„°ë¥¼ GR00Tê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        
        Args:
            observations: ì›ë³¸ ê´€ì°° ë°ì´í„°
            
        Returns:
            GR00T í˜•ì‹ì˜ ë°ì´í„°
        """
        gr00t_data = {}
        
        # ë¹„ë””ì˜¤ ë°ì´í„° ë³€í™˜
        if 'video' in observations:
            video_tensor = observations['video']
            if isinstance(video_tensor, torch.Tensor):
                # (B, N_cameras, C, H, W) -> ê° ì¹´ë©”ë¼ë³„ë¡œ ë¶„ë¦¬
                if video_tensor.ndim == 5:  # (B, N_cameras, C, H, W)
                    batch_size, num_cameras, channels, height, width = video_tensor.shape
                    
                    # ê° ì¹´ë©”ë¼ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ê°œë³„ í‚¤ë¡œ ì œê³µ
                    video_keys = self.data_config.video_keys
                    for i, key in enumerate(video_keys):
                        if i < num_cameras:
                            # (B, C, H, W) -> (B, H, W, C) -> numpy array
                            camera_data = video_tensor[:, i]  # (B, C, H, W)
                            camera_data = camera_data.permute(0, 2, 3, 1)  # (B, H, W, C)
                            camera_data = (camera_data * 255).to(torch.uint8).cpu().numpy()
                            gr00t_data[key] = camera_data
                        else:
                            # ì¹´ë©”ë¼ê°€ ë¶€ì¡±í•œ ê²½ìš° ë¹ˆ ë°ì´í„° ìƒì„±
                            gr00t_data[key] = np.zeros((batch_size, height, width, channels), dtype=np.uint8)
                else:
                    self.logger.warning(f"Unexpected video tensor shape: {video_tensor.shape}")
                    # ê¸°ë³¸ ë¹„ë””ì˜¤ í‚¤ì— ë¹ˆ ë°ì´í„° ì œê³µ
                    for key in self.data_config.video_keys:
                        gr00t_data[key] = np.zeros((1, 224, 224, 3), dtype=np.uint8)
        
        # ìƒíƒœ ë°ì´í„°
        if 'state' in observations:
            gr00t_data['state'] = observations['state']
        
        # ì•¡ì…˜ ë°ì´í„°
        if 'action' in observations:
            gr00t_data['action'] = observations['action']
        
        # ì–¸ì–´ ë°ì´í„°
        if 'language' in observations:
            gr00t_data['language'] = observations['language']
        
        return gr00t_data
    
    def get_action_from_pipeline(self) -> Dict[str, Any]:
        """
        ë°ì´í„° íŒŒì´í”„ë¼ì¸ìœ¼ë¡œë¶€í„° ì•¡ì…˜ ì˜ˆì¸¡
        
        Returns:
            ì˜ˆì¸¡ëœ ì•¡ì…˜ ë”•ì…”ë„ˆë¦¬ ë˜ëŠ” None
        """
        if self.data_pipeline is None:
            self.logger.error("Data pipeline not started")
            return self._get_safe_action()
        gr00t_input = self.data_pipeline.get_groot_input()
        if gr00t_input is None:
            self.logger.warning("No data from pipeline")
            return self._get_safe_action()
        return self.get_action_from_observations(gr00t_input)
    
    def _postprocess_action(self, action_dict: Dict[str, Any]) -> Dict[str, Any]:
        """ì•¡ì…˜ í›„ì²˜ë¦¬"""
        def process_value(value):
            if isinstance(value, torch.Tensor):
                if value.dtype == torch.bool:
                    value = value.float()
                return value.detach().cpu().numpy()
            elif isinstance(value, np.ndarray):
                return value
            elif isinstance(value, dict):
                return {k: process_value(v) for k, v in value.items()}
            elif isinstance(value, list):
                return [process_value(v) for v in value]
            else:
                try:
                    return np.array(value)
                except Exception:
                    return str(value)
        return {k: process_value(v) for k, v in action_dict.items()}
    
    def _get_safe_action(self) -> Dict[str, Any]:
        """ì•ˆì „í•œ ê¸°ë³¸ ì•¡ì…˜ (ì—ëŸ¬ ì‹œ ì‚¬ìš©)"""
        # ëª¨ë“  ê´€ì ˆê³¼ ì—”ë“œì´í™í„°ë¥¼ í˜„ì¬ ìœ„ì¹˜ë¡œ ìœ ì§€
        safe_action = {}
        action_keys = getattr(self.data_config, "action_keys", [
            "action.left_arm_joint_position",
            "action.right_arm_joint_position",
            "action.left_effector_position",
            "action.right_effector_position"
        ])
        for action_key in action_keys:
            if "joint_position" in action_key:
                safe_action[action_key] = np.zeros(7, dtype=np.float32)
            elif "effector_position" in action_key:
                safe_action[action_key] = np.zeros(6, dtype=np.float32)
        return safe_action
    
    def set_training_mode(self, training: bool = True):
        """í›ˆë ¨/í‰ê°€ ëª¨ë“œ ì„¤ì •"""
        if hasattr(self.policy, 'model'):
            if training:
                self.policy.model.train()
            else:
                self.policy.model.eval()
        
        # Transformë„ ëª¨ë“œ ì„¤ì •
        if training:
            self.modality_transform.train()
        else:
            self.modality_transform.eval()
        
        self.logger.info(f"Set to {'training' if training else 'evaluation'} mode")
    
    def get_modality_config(self) -> Dict[str, ModalityConfig]:
        """ëª¨ë‹¬ë¦¬í‹° ì„¤ì • ë°˜í™˜"""
        return self.policy.get_modality_config()
    
    def get_performance_stats(self) -> Dict[str, float]:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        elapsed = time.time() - self.start_time
        avg_inference_time = (self.total_inference_time / self.total_inferences 
                             if self.total_inferences > 0 else 0)
        inferences_per_second = self.total_inferences / elapsed if elapsed > 0 else 0
        
        return {
            'total_inferences': self.total_inferences,
            'avg_inference_time_ms': avg_inference_time * 1000,
            'inferences_per_second': inferences_per_second,
            'uptime_seconds': elapsed
        }
    
    def get_model_info(self) -> Dict[str, Any]:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜"""
        info = {
            'model_path': str(self.model_path),
            'embodiment_name': self.embodiment_name,
            'device': str(self.device),
            'denoising_steps': getattr(self.policy, 'denoising_steps', None)
        }
        
        if hasattr(self.policy, 'model'):
            model = self.policy.model
            info.update({
                'model_type': type(model).__name__,
                'action_horizon': getattr(model, 'action_horizon', None),
                'state_horizon': getattr(model, 'state_horizon', None)
            })
        
        return info
    
    def validate_observations(self, observations: Dict[str, Any]) -> bool:
        """ê´€ì°° ë°ì´í„° ìœ íš¨ì„± ê²€ì¦"""
        try:
            # í•„ìˆ˜ í‚¤ í™•ì¸
            required = set(self.modality_config.keys())
            if not required.issubset(observations):
                missing = required - set(observations)
                self.logger.error(f"Missing required keys: {missing}")
                return False
            
            # ë°ì´í„° íƒ€ì… ë° í¬ê¸° í™•ì¸
            for key, value in observations.items():
                if not isinstance(value, (np.ndarray, torch.Tensor)):
                    self.logger.error(f"Invalid data type for {key}: {type(value)}")
                    return False
                
                if hasattr(value, 'shape') and len(value.shape) == 0:
                    self.logger.error(f"Scalar value not allowed for {key}")
                    return False
            
            return True
            
        except Exception as e:
            self.logger.error(f"Validation error: {e}")
            return False
    
    def __enter__(self):
        """Context manager ì§„ì…"""
        self.start_data_pipeline()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Context manager ì¢…ë£Œ"""
        self.stop_data_pipeline()


# í¸ì˜ìš© í•¨ìˆ˜ë“¤
def create_dual_piper_interface(
    model_path: str,
    denoising_steps: Optional[int] = None,
    device: str = "cuda",
    use_mock_data: bool = False
) -> DualPiperGR00TInterface:
    """Dual Piper GR00T ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    return DualPiperGR00TInterface(
        model_path=model_path,
        embodiment_name="dual_piper_arm",
        denoising_steps=denoising_steps,
        device=device,
        use_mock_data=use_mock_data
    )


def test_gr00t_interface():
    """GR00T ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
    print("Testing GR00T interface...")
    
    # Mock ëª¨ë¸ ê²½ë¡œ (ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹œ ì‹¤ì œ ê²½ë¡œ ì‚¬ìš©)
    model_path = "nvidia/gr00t-1.5b"  # ì˜ˆì‹œ ê²½ë¡œ
    
    try:
        # ì¸í„°í˜ì´ìŠ¤ ìƒì„± (Mock ëª¨ë“œ)
        interface = DualPiperGR00TInterface(
            model_path=model_path,
            embodiment_name="dual_piper_arm",  # ì‹¤ì œë¡œëŠ” ì¡´ì¬í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ
            use_mock_data=True
        )
        
        print("âœ… Interface created successfully")
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        model_info = interface.get_model_info()
        print(f"Model info: {model_info}")
        
        # ëª¨ë‹¬ë¦¬í‹° ì„¤ì • í™•ì¸
        modality_config = interface.get_modality_config()
        print(f"Modality config keys: {list(modality_config.keys())}")
        
        # Mock ê´€ì°° ë°ì´í„° ìƒì„±
        mock_observations = {
            'video': np.random.randint(0, 255, (1, 3, 224, 224), dtype=np.uint8),
            'state': np.random.uniform(-1, 1, (1, 64)).astype(np.float32),
            'language': "Pick up the red cube"
        }
        
        print("\nğŸ” Testing action prediction...")
        
        # ë°ì´í„° ê²€ì¦
        is_valid = interface.validate_observations(mock_observations)
        print(f"Observations valid: {is_valid}")
        
        if is_valid:
            # ì•¡ì…˜ ì˜ˆì¸¡
            action = interface.get_action_from_observations(mock_observations)
            print(f"Predicted action keys: {list(action.keys())}")
            
            for key, value in action.items():
                if hasattr(value, 'shape'):
                    print(f"  {key}: {value.shape}")
        
        # ì„±ëŠ¥ í†µê³„
        stats = interface.get_performance_stats()
        print(f"\nPerformance stats: {stats}")
        
    except Exception as e:
        print(f"âŒ Test failed: {e}")
        print("Note: This is expected if the actual model path doesn't exist")


if __name__ == "__main__":
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_gr00t_interface()